# -*- coding: utf-8 -*-

from datetime import datetime
from collections import OrderedDict
from urlparse import urlparse, urljoin

from sqlalchemy.exc import ProgrammingError
from flask import abort, redirect, render_template, request, Response, url_for, g, flash, jsonify, Markup
from coaster.utils import getbool, parse_isoformat, for_tsquery
from coaster.views import render_with, requestargs
from baseframe import _  # , dogpile

from .. import app, lastuser
from ..models import (db, JobCategory, JobPost, JobType, POST_STATE, newlimit, agelimit, JobLocation, Board, Filterset,
    Domain, Location, Tag, JobPostTag, Campaign, CAMPAIGN_POSITION, CURRENCY, JobApplication, starred_job_table, BoardJobPost)
from ..views.helper import (getposts, getallposts, gettags, location_geodata, load_viewcounts, session_jobpost_ab,
    bgroup, make_pay_graph, index_is_paginated, get_post_viewcounts, get_max_counts)
from ..uploads import uploaded_logos
from ..utils import string_to_number


def stickie_dict(post, url, pinned=False, show_viewcounts=False, show_pay=False,
        starred=False, is_bgroup=None):
    if show_viewcounts or show_pay:
        post_viewcounts = get_post_viewcounts(post.id)
    result = {
        'headline': post.headlineb if is_bgroup else post.headline,
        'url': url,
        'pinned': pinned,
        'starred': starred,
        'date': post.datetime.isoformat() + 'Z',
        'location': post.location,
        'parsed_location': post.parsed_location,
        'company_name': post.company_name,
        'company_logo': post.url_for('logo'),
        }
    if show_viewcounts:
        result['viewcounts'] = {
            'listed': post_viewcounts['impressions'],
            'viewed': post_viewcounts['viewed'],
            'opened': post_viewcounts['opened'],
            'applied': post_viewcounts['applied']
        }
    if show_pay:
        result['pay'] = post_viewcounts['pay_label']
    return result


def json_index(data):
    pinsandposts = data['pinsandposts']
    grouped = data['grouped']
    is_siteadmin = data['is_siteadmin']
    loadmore = data['loadmore']

    result = {
        'grouped': [],
        'posts': [],
        'loadmore': loadmore.isoformat() + 'Z' if loadmore else None
        }
    if grouped:
        for grouping, group in grouped.items():
            rgroup = {
                'url': None,
                'posts': []
                }

            # First, process the first item to get a URL for the entire group
            pinned, post, is_bgroup = group[0]
            if len(group) == 1:
                rgroup['url'] = post.url_for(b=is_bgroup)
            elif grouping[0] in ('sd', 'nd'):  # Grouped by domain
                rgroup['url'] = url_for('browse_by_domain', domain=grouping[1])
            elif grouping[0] in ('se', 'ne'):  # Grouped by email (webmail user)
                rgroup['url'] = url_for('browse_by_email', md5sum=grouping[1])

            for pinned, post, is_bgroup in group:
                rgroup['posts'].append(stickie_dict(
                    post=post, url=post.url_for(b=is_bgroup), pinned=pinned, is_bgroup=is_bgroup,
                    show_viewcounts=is_siteadmin or g.user and g.user.flags.get('is_employer_month'),
                    show_pay=is_siteadmin, starred=g.user and post.id in g.starred_ids
                    ))
            result['grouped'].append(rgroup)
    if pinsandposts:
        for pinned, post, is_bgroup in pinsandposts:
            result['posts'].append(stickie_dict(
                post=post, url=post.url_for(b=is_bgroup), pinned=pinned, is_bgroup=is_bgroup,
                show_viewcounts=is_siteadmin or g.user and g.user.flags.get('is_employer_month'),
                show_pay=is_siteadmin, starred=g.user and post.id in g.starred_ids
                ))

    return jsonify(result)


def fetch_jobposts(request_args, request_values, filters, is_index, board, board_jobs, gkiosk, basequery, md5sum, domain, location, title, showall, statusfilter, batched, ageless, template_vars, search_query=None, query_string=None):
    if basequery is None:
        basequery = JobPost.query

    # Apply request.args filters
    data_filters = {}
    f_types = filters.get('t') or request_args.getlist('t')
    while '' in f_types:
        f_types.remove('')
    if f_types:
        data_filters['types'] = f_types
        basequery = basequery.join(JobType).filter(JobType.name.in_(f_types))
    f_categories = filters.get('c') or request_args.getlist('c')
    while '' in f_categories:
        f_categories.remove('')
    if f_categories:
        data_filters['categories'] = f_categories
        basequery = basequery.join(JobCategory).filter(JobCategory.name.in_(f_categories))

    f_domains = filters.get('d') or request_args.getlist('d')
    while '' in f_domains:
        f_domains.remove('')
    if f_domains:
        basequery = basequery.join(Domain).filter(Domain.name.in_(f_domains))

    f_tags = filters.get('k') or request_args.getlist('k')
    while '' in f_tags:
        f_tags.remove('')
    if f_tags:
        basequery = basequery.join(JobPostTag).join(Tag).filter(Tag.name.in_(f_tags))

    data_filters['location_names'] = r_locations = filters.get('l') or request_args.getlist('l')
    if location:
        r_locations.append(location['geonameid'])
    f_locations = []
    remote_location = getbool(filters.get('anywhere') or request_args.get('anywhere')) or False
    if remote_location:
        data_filters['location_names'].append('anywhere')
    for rl in r_locations:
        if isinstance(rl, int) and rl > 0:
            f_locations.append(rl)
        elif rl == 'anywhere':
            remote_location = True
        elif rl.isdigit():
            f_locations.append(int(rl))
        elif rl:
            ld = location_geodata(rl)
            if ld:
                f_locations.append(ld['geonameid'])
    remote_location_query = basequery.filter(JobPost.remote_location == True)  # NOQA
    if f_locations:
        locations_query = basequery.join(JobLocation).filter(JobLocation.geonameid.in_(f_locations))
    else:
        locations_query = basequery.join(JobLocation)
    if f_locations and remote_location:
        data_filters['locations'] = f_locations
        data_filters['anywhere'] = True
        recency = JobPost.state.LISTED
        basequery = locations_query.filter(recency).union(remote_location_query.filter(recency))
    elif f_locations:
        data_filters['locations'] = f_locations
        basequery = locations_query
    elif remote_location:
        data_filters['anywhere'] = True
        # Only works as a positive filter: you can't search for jobs that are NOT anywhere
        basequery = remote_location_query

    currency = filters.get('currency') or request_args.get('currency')
    if currency in CURRENCY.keys():
        data_filters['currency'] = currency
        basequery = basequery.filter(JobPost.pay_currency == currency)
        pay_graph = currency
    else:
        pay_graph = False
    if getbool(filters.get('equity') or request_args.get('equity')):
        # Only works as a positive filter: you can't search for jobs that DON'T pay in equity
        data_filters['equity'] = True
        basequery = basequery.filter(JobPost.pay_equity_min != None)  # NOQA

    if filters.get('pay') or 'pay' in request_args or ('pmin' in request_args and 'pmax' in request_args):
        if 'pay' in request_args or filters.get('pay'):
            f_pay = filters['pay'] if filters.get('pay') else string_to_number(request_args['pay'])
            if f_pay is not None:
                f_min = int(f_pay * 0.90)
                f_max = int(f_pay * 1.30)
            else:
                f_min = None
                f_max = None
        else:
            # Legacy URL with min/max values
            f_min = string_to_number(request_args['pmin'])
            f_max = string_to_number(request_args['pmax'])
            f_pay = f_min  # Use min for pay now
        if f_pay is not None and f_min is not None and f_max is not None:
            data_filters['pay'] = f_pay
            basequery = basequery.filter(JobPost.pay_cash_min < f_max, JobPost.pay_cash_max >= f_min)
    else:
        f_pay = None
        f_min = None
        f_max = None

    if getbool(request_args.get('archive')):
        ageless = True
        data_filters['archive'] = True
        statusfilter = JobPost.state.ARCHIVED

    if query_string:
        data_filters['query'] = search_query
        data_filters['query_string'] = query_string
        basequery = basequery.filter(JobPost.search_vector.match(search_query, postgresql_regconfig='english'))

    if data_filters:
        showall = True
        batched = True

    posts = getposts(basequery, pinned=True, showall=showall, statusfilter=statusfilter, ageless=ageless).all()

    if getbool(request_args.get('embed')):
        embed = True
        if posts:
            if request_args.get('limit'):
                posts = posts[:int(request_args.get('limit'))]
            else:
                posts = posts[:8]
    else:
        embed = False

    if posts:
        employer_name = posts[0].company_name
    else:
        employer_name = u'a single employer'

    jobpost_ab = session_jobpost_ab()
    if is_index and posts and not gkiosk and not embed:
        # Group posts by email_domain on index page only, when not in kiosk mode
        grouped = OrderedDict()
        for post in posts:
            pinned = post.pinned
            if board is not None:
                blink = board_jobs.get(post.id)  # board_jobs only contains the last 30 days, no archive
                if blink is not None:
                    pinned = blink.pinned
            if pinned:
                # Make pinned posts appear in a group of one
                grouped.setdefault(('s', post.hashid), []).append(
                    (pinned, post, bgroup(jobpost_ab, post)))
            elif post.state.ANNOUNCEMENT:
                # Make announcements also appear in a group of one
                grouped.setdefault(('a', post.hashid), []).append(
                    (pinned, post, bgroup(jobpost_ab, post)))
            elif post.domain.is_webmail:
                grouped.setdefault(('ne', post.md5sum), []).append(
                    (pinned, post, bgroup(jobpost_ab, post)))
            else:
                grouped.setdefault(('nd', post.email_domain), []).append(
                    (pinned, post, bgroup(jobpost_ab, post)))
        pinsandposts = None
    else:
        grouped = None
        if board:
            pinsandposts = []
            for post in posts:
                pinned = post.pinned
                if board is not None:
                    blink = board_jobs.get(post.id)  # board_jobs only contains the last 30 days, no archive
                    if blink is not None:
                        pinned = blink.pinned
                pinsandposts.append((pinned, post, bgroup(jobpost_ab, post)))
        else:
            pinsandposts = [(post.pinned, post, bgroup(jobpost_ab, post)) for post in posts]

    # Pick a header campaign (only if not kiosk or an XHR reload)
    pay_graph_data = None

    loadmore = False
    if batched:
        # Figure out where the batch should start from
        startdate = None
        if 'startdate' in request_values:
            try:
                startdate = parse_isoformat(request_values['startdate'])
            except ValueError:
                pass

        batchsize = 32

        # list of posts that were pinned at the time of first load
        pinned_hashids = request_args.getlist('ph')
        # Depending on the display mechanism (grouped or ungrouped), extract the batch
        if grouped:
            if not startdate:
                startindex = 0
                for row in grouped.values():
                    # break when a non-pinned post is encountered
                    if (not row[0][0]):
                        break
                    else:
                        pinned_hashids.append(row[0][1].hashid)
            else:
                # Loop through group looking for start of next batch. See below to understand the
                # nesting structure of 'grouped'
                for startindex, row in enumerate(grouped.values()):
                    # Skip pinned posts when looking for starting index
                    if (row[0][1].hashid not in pinned_hashids and row[0][1].datetime < startdate):
                        break

            batch = grouped.items()[startindex:startindex + batchsize]
            if startindex + batchsize < len(grouped):
                # Get the datetime of the last group's first item
                # batch = [((type, domain), [(pinned, post, bgroup), ...])]
                # batch[-1] = ((type, domain), [(pinned, post, bgroup), ...])
                # batch[-1][1] = [(pinned, post, bgroup), ...]
                # batch[-1][1][0] = (pinned, post, bgroup)
                # batch[-1][1][0][1] = post
                loadmore = batch[-1][1][0][1].datetime
            grouped = OrderedDict(batch)
        elif pinsandposts:
            if not startdate:
                startindex = 0
                for row in pinsandposts:
                    # break when a non-pinned post is encountered
                    if not row[0]:
                        break
                    else:
                        pinned_hashids.append(row[1].hashid)
            else:
                for startindex, row in enumerate(pinsandposts):
                    # Skip pinned posts when looking for starting index
                    if (row[1].hashid not in pinned_hashids and row[1].datetime < startdate):
                        break

            batch = pinsandposts[startindex:startindex + batchsize]
            if startindex + batchsize < len(pinsandposts):
                # batch = [(pinned, post), ...]
                loadmore = batch[-1][1].datetime
            pinsandposts = batch

    query_params = request_args.to_dict(flat=False)
    if loadmore:
        query_params.update({'startdate': loadmore.isoformat() + 'Z', 'ph': pinned_hashids})
    if location:
        data_filters['location_names'].append(location['name'])
        query_params.update({'l': location['name']})

    if pay_graph:
        pay_graph_data = make_pay_graph(pay_graph, posts, rmin=f_min, rmax=f_max)

    return dict(posts=posts, pinsandposts=pinsandposts, grouped=grouped, newlimit=newlimit, title=title,
        md5sum=md5sum, domain=domain, location=location, employer_name=employer_name,
        showall=showall, f_locations=f_locations, loadmore=loadmore,
        query_params=query_params, data_filters=data_filters,
        pay_graph_data=pay_graph_data, paginated=index_is_paginated(),
        template_vars=template_vars, embed=embed)


# @dogpile.region('hasjob_index')
def fetch_cached_jobposts(request_args, request_values, filters, is_index, board, board_jobs, gkiosk, basequery, md5sum, domain, location, title, showall, statusfilter, batched, ageless, template_vars, search_query=None, query_string=None):
    return fetch_jobposts(request_args, request_values, filters, is_index, board, board_jobs, gkiosk, basequery, md5sum, domain, location, title, showall, statusfilter, batched, ageless, template_vars, search_query, query_string)


@app.route('/', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/', methods=['GET', 'POST'])
@render_with({'text/html': 'index.html.jinja2', 'application/json': json_index}, json=False)
def index(basequery=None, filters={}, md5sum=None, tag=None, domain=None, location=None, title=None, showall=True, statusfilter=None, batched=True, ageless=False, cached=False, query_string=None, filterset=None, template_vars={}):
    now = datetime.utcnow()
    is_siteadmin = lastuser.has_permission('siteadmin')
    board = g.board

    if board:
        board_jobs = {r.jobpost_id: r for r in
            BoardJobPost.query.join(BoardJobPost.jobpost).filter(
                BoardJobPost.board == g.board, JobPost.state.LISTED).options(
                    db.load_only('jobpost_id', 'pinned')).all()
        }

    else:
        board_jobs = {}

    if basequery is None:
        is_index = True
    else:
        is_index = False
    if basequery is None and not (g.user or g.kiosk or (board and not board.require_login)):
        showall = False
        batched = False

    # `query_string` is user-supplied
    # `search_query` is PostgreSQL syntax
    if not query_string:
        query_string = request.args.get('q')
    if query_string:
        search_query = for_tsquery(query_string)
        try:
            # TODO: Can we do syntax validation without a database roundtrip?
            db.session.query(db.func.to_tsquery(search_query)).all()
        except ProgrammingError:
            db.session.rollback()
            g.event_data['search_syntax_error'] = (query_string, search_query)
            if not request.is_xhr:
                flash(_(u"Search terms ignored because this didn’t parse: {query}").format(query=search_query), 'danger')
            search_query = None
    else:
        search_query = None

    if cached:
        data = fetch_cached_jobposts(request.args, request.values, filters, is_index, board, board_jobs, g.kiosk, basequery, md5sum, domain, location, title, showall, statusfilter, batched, ageless, template_vars, search_query, query_string)
    else:
        data = fetch_jobposts(request.args, request.values, filters, is_index, board, board_jobs, g.kiosk, basequery, md5sum, domain, location, title, showall, statusfilter, batched, ageless, template_vars, search_query, query_string)

    if data['data_filters']:
        # For logging
        g.event_data['filters'] = data['data_filters']

    if g.user:
        g.starred_ids = set(g.user.starred_job_ids(agelimit if not ageless else None))
    else:
        g.starred_ids = set()

    if is_siteadmin or (g.user and g.user.flags.get('is_employer_month')):
        load_viewcounts(data['posts'])
        show_viewcounts = True
    else:
        show_viewcounts = False

    if data['grouped']:
        g.impressions = {post.id: (pinflag, post.id, is_bgroup)
            for group in data['grouped'].itervalues()
            for pinflag, post, is_bgroup in group}
    elif data['pinsandposts']:
        g.impressions = {post.id: (pinflag, post.id, is_bgroup) for pinflag, post, is_bgroup in data['pinsandposts']}

    if not g.kiosk:
        if g.preview_campaign:
            header_campaign = g.preview_campaign
        else:
            geonameids = g.user_geonameids + data['f_locations']
            header_campaign = Campaign.for_context(CAMPAIGN_POSITION.HEADER, board=g.board, user=g.user,
                anon_user=g.anon_user, geonameids=geonameids)
    else:
        header_campaign = None

    # Test values for development:
    # if not g.user_geonameids:
    #     g.user_geonameids = [1277333, 1277331, 1269750]
    if not location and 'l' not in request.args and g.user_geonameids and (g.user or g.anon_user) and (
            (not g.board.auto_locations) if g.board else True):
        # No location filters? Prompt the user
        ldata = location_geodata(g.user_geonameids)
        location_prompts = [ldata[geonameid] for geonameid in g.user_geonameids if geonameid in ldata]
    else:
        location_prompts = []

    data['header_campaign'] = header_campaign
    data['now'] = now
    data['is_siteadmin'] = is_siteadmin
    data['location_prompts'] = location_prompts
    if data['domain'] and data['domain'] not in db.session:
        data['domain'] = db.session.merge(data['domain'])
    data['show_viewcounts'] = show_viewcounts

    max_counts = get_max_counts()
    data['max_impressions'] = max_counts['max_impressions']
    data['max_views'] = max_counts['max_views']
    data['max_opens'] = max_counts['max_opens']
    data['max_applied'] = max_counts['max_applied']

    if filterset:
        data['filterset'] = filterset

    return data


@app.route('/drafts', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/drafts', methods=['GET', 'POST'])
@lastuser.requires_login
def browse_drafts():
    basequery = JobPost.query.filter_by(user=g.user)
    return index(basequery=basequery, ageless=True, statusfilter=JobPost.state.UNPUBLISHED, cached=False)


@app.route('/my', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/my', methods=['GET', 'POST'])
@lastuser.requires_login
def my_posts():
    basequery = JobPost.query.filter_by(user=g.user)
    return index(basequery=basequery, ageless=True, statusfilter=JobPost.state.MY, cached=False)


@app.route('/bookmarks', subdomain='<subdomain>')
@app.route('/bookmarks')
@lastuser.requires_login
def bookmarks():
    basequery = JobPost.query.join(starred_job_table).filter(starred_job_table.c.user_id == g.user.id)
    return index(basequery=basequery, ageless=True, statusfilter=JobPost.state.ARCHIVED, cached=False)


@app.route('/applied', subdomain='<subdomain>')
@app.route('/applied')
@lastuser.requires_login
def applied():
    basequery = JobPost.query.join(JobApplication).filter(JobApplication.user == g.user)
    return index(basequery=basequery, ageless=True, statusfilter=JobPost.state.ARCHIVED, cached=False)


@app.route('/type/<name>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/type/<name>', methods=['GET', 'POST'])
def browse_by_type(name):
    if name == 'all':
        return redirect(url_for('index'))
    return redirect(url_for('index', t=name), code=302)


@app.route('/<domain>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/<domain>', methods=['GET', 'POST'])
def browse_by_domain(domain):
    if not domain or '.' not in domain:
        abort(404)
    obj = Domain.get(domain)
    if not obj:
        abort(404)
    if obj.is_banned:
        abort(410)
    basequery = JobPost.query.join(Domain).filter(JobPost.domain == obj)
    return index(basequery=basequery, domain=obj, title=obj.use_title, showall=True)


@app.route('/at/<domain>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/at/<domain>', methods=['GET', 'POST'])
def browse_by_domain_legacy(domain):
    return redirect(url_for('browse_by_domain', domain=domain), code=301)


@app.route('/category/<name>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/category/<name>', methods=['GET', 'POST'])
def browse_by_category(name):
    if name == 'all':
        return redirect(url_for('index'))
    return redirect(url_for('index', c=name), code=302)


@app.route('/by/<md5sum>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/by/<md5sum>', methods=['GET', 'POST'])
def browse_by_email(md5sum):
    if not md5sum:
        abort(404)
    basequery = JobPost.query.filter_by(md5sum=md5sum)
    jobpost = basequery.first_or_404()
    jobpost_user = jobpost.user
    return index(basequery=basequery, md5sum=md5sum, showall=True, cached=False, template_vars={'jobpost_user': jobpost_user})


@app.route('/in/<location>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/in/<location>', methods=['GET', 'POST'])
def browse_by_location(location):
    loc = Location.get(location, g.board)
    if loc:
        geodata = {'geonameid': loc.id, 'name': loc.name, 'use_title': loc.title, 'description': Markup(loc.description)}
    else:
        return redirect(url_for('index', l=location), code=302)
    if location != geodata['name']:
        return redirect(url_for('browse_by_location', location=geodata['name']))
    return index(location=geodata, title=geodata['use_title'])


@app.route('/in/anywhere', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/in/anywhere', methods=['GET', 'POST'])
def browse_by_anywhere():
    return redirect(url_for('index', l='anywhere'), code=302)


@app.route('/tag/<tag>', methods=['GET', 'POST'], subdomain='<subdomain>')
@app.route('/tag/<tag>', methods=['GET', 'POST'])
def browse_by_tag(tag):
    tag = Tag.query.filter_by(name=tag).first_or_404()
    basequery = JobPost.query.filter(db.and_(
        JobPostTag.jobpost_id == JobPost.id, JobPostTag.tag == tag))
    return index(basequery=basequery, tag=tag, title=tag.title)


@app.route('/tag', subdomain='<subdomain>')
@app.route('/tag')
def browse_tags():
    return render_template('tags.html.jinja2', tags=gettags(alltime=getbool(request.args.get('all'))))


# POST is required for pagination
@app.route('/f/<name>', subdomain='<subdomain>', methods=['GET', 'POST'])
@app.route('/f/<name>', methods=['GET', 'POST'])
@Filterset.is_url_for('view')
def filterset_view(name):
    filterset = Filterset.get(g.board, name)
    if not filterset:
        abort(404)
    return index(filters=filterset.to_filters(translate_geonameids=True),
        query_string=filterset.keywords, filterset=filterset, title=filterset.title)


@app.route('/opensearch.xml', subdomain='<subdomain>')
@app.route('/opensearch.xml')
def opensearch():
    return render_template('opensearch.xml')


@app.route('/feed', subdomain='<subdomain>')
@app.route('/feed')
def feed(basequery=None, type=None, category=None, md5sum=None, domain=None, location=None, tag=None, title=None):
    title = "All jobs"
    if type:
        title = type.title
    elif category:
        title = category.title
    elif md5sum or domain:
        title = u"Jobs at a single employer"
    elif location:
        title = u"Jobs in {location}".format(location=location['use_title'])
    elif tag:
        title = u"Jobs tagged {tag}".format(tag=title)
    posts = list(getposts(basequery, showall=True, limit=100))
    if posts:  # Can't do this unless posts is a list
        updated = posts[0].datetime.isoformat() + 'Z'
        if md5sum:
            title = posts[0].company_name
    else:
        updated = datetime.utcnow().isoformat() + 'Z'
    return Response(render_template('feed-atom.xml', posts=posts, updated=updated, title=title),
        content_type='application/atom+xml; charset=utf-8')


@app.route('/feed/indeed', subdomain='<subdomain>')
@app.route('/feed/indeed')
def feed_indeed():
    title = "All jobs"
    posts = list(getposts(None, showall=True))
    if posts:  # Can't do this unless posts is a list
        updated = posts[0].datetime.isoformat() + 'Z'
    else:
        updated = datetime.utcnow().isoformat() + 'Z'
    return Response(render_template('feed-indeed.xml', posts=posts, updated=updated, title=title),
        content_type='textxml; charset=utf-8')


@app.route('/type/<name>/feed', subdomain='<subdomain>')
@app.route('/type/<name>/feed')
def feed_by_type(name):
    if name == 'all':
        return redirect(url_for('feed'))
    ob = JobType.query.filter_by(name=name).first_or_404()
    basequery = JobPost.query.filter_by(type_id=ob.id)
    return feed(basequery=basequery, type=ob)


@app.route('/category/<name>/feed', subdomain='<subdomain>')
@app.route('/category/<name>/feed')
def feed_by_category(name):
    if name == 'all':
        return redirect(url_for('feed'))
    ob = JobCategory.query.filter_by(name=name).first_or_404()
    basequery = JobPost.query.filter_by(category_id=ob.id)
    return feed(basequery=basequery, category=ob)


@app.route('/by/<md5sum>/feed', subdomain='<subdomain>')
@app.route('/by/<md5sum>/feed')
def feed_by_email(md5sum):
    if not md5sum:
        abort(404)
    basequery = JobPost.query.filter_by(md5sum=md5sum)
    if basequery.isempty():
        abort(404)
    return feed(basequery=basequery, md5sum=md5sum)


@app.route('/at/<domain>/feed', subdomain='<subdomain>')
@app.route('/at/<domain>/feed')
def feed_by_domain_legacy(domain):
    return redirect(url_for('feed_by_domain', domain=domain), code=301)


@app.route('/<domain>/feed', subdomain='<subdomain>')
@app.route('/<domain>/feed')
def feed_by_domain(domain):
    if not domain:
        abort(404)
    basequery = JobPost.query.filter_by(email_domain=domain)
    return feed(basequery=basequery, domain=domain)


@app.route('/in/<location>/feed', subdomain='<subdomain>')
@app.route('/in/<location>/feed')
def feed_by_location(location):
    geodata = location_geodata(location)
    if not geodata:
        abort(404)
    basequery = JobPost.query.filter(db.and_(
        JobLocation.jobpost_id == JobPost.id, JobLocation.geonameid == geodata['geonameid']))
    return feed(basequery=basequery, location=geodata)


@app.route('/in/anywhere/feed', subdomain='<subdomain>')
@app.route('/in/anywhere/feed')
def feed_by_anywhere():
    basequery = JobPost.query.filter(JobPost.remote_location == True)  # NOQA
    return feed(basequery=basequery)


@app.route('/tag/<tag>/feed', subdomain='<subdomain>')
@app.route('/tag/<tag>/feed')
def feed_by_tag(tag):
    tag = Tag.query.filter_by(name=tag).first_or_404()
    basequery = JobPost.query.filter(db.and_(
        JobPostTag.jobpost_id == JobPost.id, JobPostTag.tag == tag))
    return feed(basequery=basequery, tag=tag, title=tag.title)


@app.route('/archive')
def archive():
    def sortarchive(order_by):
        current_order_by = request.args.get('order_by')
        reverse = request.args.get('reverse')
        if order_by == current_order_by:
            if reverse is None:
                reverse = False
            try:
                reverse = bool(int(reverse))
            except ValueError:
                reverse = False
            reverse = int(not reverse)
        return url_for('archive', order_by=order_by,
            reverse=reverse,
            start=request.args.get('start'),
            limit=request.args.get('limit'))

    order_by = {
        'date': JobPost.datetime,
        'headline': JobPost.headline,
        'company': JobPost.company_name,
        'location': JobPost.location,
        }.get(request.args.get('order_by'))
    reverse = request.args.get('reverse')
    start = request.args.get('start', 0)
    limit = request.args.get('limit', 100)
    if order_by is None and reverse is None:
        order_by = JobPost.datetime
        reverse = True
    try:
        if reverse is not None:
            reverse = bool(int(reverse))
    except ValueError:
        reverse = None
    try:
        if start is not None:
            start = int(start)
    except ValueError:
        start = 0
    try:
        if limit is not None:
            limit = int(limit)
    except ValueError:
        limit = 100
    count, posts = getallposts(order_by=order_by, desc=reverse, start=start, limit=limit)

    if request.is_xhr:
        tmpl = 'archive_inner.html.jinja2'
    else:
        tmpl = 'archive.html.jinja2'
    return render_template(tmpl, order_by=request.args.get('order_by'),
        posts=posts, start=start, limit=limit, count=count,
        # Pass some functions
        min=min, max=max, sortarchive=sortarchive)


@app.route('/sitemap.xml', defaults={'key': None}, subdomain='<subdomain>')
@app.route('/sitemap.xml', defaults={'key': None})
@app.route('/sitemap.xml/<key>', subdomain='<subdomain>')
@app.route('/sitemap.xml/<key>')
def sitemap(key):
    authorized_sitemap = key == app.config.get('SITEMAP_KEY')

    sitemapxml = '<?xml version="1.0" encoding="UTF-8"?>\n'\
                 '<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n'
    # Add featured boards to sitemap
    board_ids = []
    for board in Board.query.filter_by(featured=True).all():
        board_ids.append(board.id)
        sitemapxml += '  <url>\n'\
                      '    <loc>%s</loc>\n' % board.url_for(_external=True) + \
                      '    <lastmod>%s</lastmod>\n' % (board.updated_at.isoformat() + 'Z') + \
                      '    <changefreq>monthly</changefreq>\n'\
                      '  </url>\n'

    # Add filtered views to sitemap
    for item in Filterset.query.all():
        sitemapxml += '  <url>\n'\
                    '    <loc>%s</loc>\n' % item.url_for(_external=True) + \
                    '    <lastmod>%s</lastmod>\n' % (item.updated_at.isoformat() + 'Z') + \
                    '    <changefreq>daily</changefreq>\n'\
                    '  </url>\n'

    # Add locations to sitemap
    for item in Location.query.filter(Location.board_id.in_(board_ids)).all():
        sitemapxml += '  <url>\n'\
                      '    <loc>%s</loc>\n' % item.url_for(_external=True) + \
                      '    <lastmod>%s</lastmod>\n' % (item.updated_at.isoformat() + 'Z') + \
                      '    <changefreq>monthly</changefreq>\n'\
                      '  </url>\n'
    # Add live posts to sitemap
    for post in getposts(showall=True):
        sitemapxml += '  <url>\n'\
                      '    <loc>%s</loc>\n' % post.url_for(_external=True) + \
                      '    <lastmod>%s</lastmod>\n' % (post.datetime.isoformat() + 'Z') + \
                      '    <changefreq>monthly</changefreq>\n'\
                      '  </url>\n'
    if authorized_sitemap:
        # Add domains to sitemap
        for domain in Domain.query.filter(
                Domain.title != None,
                Domain.description != None,
                Domain.description != ''
                ).order_by('updated_at desc').all():  # NOQA
            sitemapxml += '  <url>\n'\
                          '    <loc>%s</loc>\n' % domain.url_for(_external=True) + \
                          '    <lastmod>%s</lastmod>\n' % (domain.updated_at.isoformat() + 'Z') + \
                          '    <changefreq>monthly</changefreq>\n'\
                          '  </url>\n'
    sitemapxml += '</urlset>'
    return Response(sitemapxml, content_type='text/xml; charset=utf-8')


@app.route('/<domain>/<hashid>/logo', subdomain='<subdomain>')
@app.route('/<domain>/<hashid>/logo')
@app.route('/logo/<hashid>', defaults={'domain': None}, subdomain='<subdomain>')
@app.route('/logo/<hashid>', defaults={'domain': None})
def logoimage(domain, hashid):
    post = JobPost.query.filter_by(hashid=hashid).first_or_404()
    if not post.company_logo:
        # If there's no logo (perhaps it was deleted), don't try to show one
        abort(404)
    if post.state.UNACCEPTABLE:
        # Don't show logo if post has been rejected. Could be spam
        abort(410)
    return redirect(uploaded_logos.url(post.company_logo))


@app.route('/search', subdomain='<subdomain>')
@app.route('/search')
def search():
    return redirect(url_for('index', **request.args))


@app.route('/api/1/template/offline', subdomain='<subdomain>')
@app.route('/api/1/template/offline')
def offline():
    return render_template('offline.html.jinja2')


@app.route('/service-worker.js', methods=['GET'], subdomain='<subdomain>')
@app.route('/service-worker.js', methods=['GET'])
def sw():
    return app.send_static_file('service-worker.js')


@app.route('/manifest.json', methods=['GET'], subdomain='<subdomain>')
@app.route('/manifest.json', methods=['GET'])
def manifest():
    return Response(render_template('manifest.json.jinja2'), mimetype='application/json')


@app.route('/api/1/embed.js', methods=['GET'], subdomain='<subdomain>')
@app.route('/api/1/embed.js', methods=['GET'])
def embed():
    return app.send_static_file('embed.js')


@app.route('/api/1/oembed', methods=['GET'], subdomain='<subdomain>')
@app.route('/api/1/oembed', methods=['GET'])
@requestargs('url')
def oembed(url):
    """
    Endpoint to support oEmbed - https://oembed.com/

    Example request - http://hasjob.co/api/1/oembed?url=https://hasjob.co/

    Required for services like embed.ly
    """
    oembedjs = {}

    parsed = urlparse(url)
    if not parsed.netloc.endswith(u'hasjob.co'):
        # is this a legit hasjob domain or subdomain? if not, then return 404
        abort(404)

    boardname, _ = parsed.netloc.split('.', 1)
    if boardname == 'hasjob':
        # in case the url is https://hasjob.co/?embed=1
        boardname = 'www'

    board = Board.query.filter_by(name=boardname).first()
    if not board:
        abort(404)

    if parsed.path in ['/', '']:
        # Checking like this so that it's easier in future to embed more type of content
        oembedjs = {
            "provider_url": url_for('index', _external=True),
            "provider_name": app.config.get('SITE_TITLE'),
            "thumbnail_width": 200,
            "thumbnail_height": 200,
            "thumbnail_url": url_for('static', filename='img/hasjob-logo-200x200.png', _external=True),
            "author_name": app.config.get('SITE_TITLE'),
            "author_url": urljoin(url_for('index', _external=True), "humans.txt"),
            "title": ' | '.join([board.title, board.caption]),
            "html": "<iframe src='{url}&{query}'>".format(url=board.url_for('oembed'), query=parsed.query),
            "version": "1.0",
            "type": "rich"
        }
    return jsonify(oembedjs)
